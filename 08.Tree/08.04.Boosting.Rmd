---
title: "8.4. Boosting"
output: html_notebook
---

# 1. load the data
```{r}
library(gbm)
library(MASS)
attach(Boston)
set.seed(2)
dim(Boston)
train = sample(1:nrow(Boston), 300)
boston.train = Boston[train, ]
boston.test = Boston[-train, ]
medv.test = medv[-train]
```

# 2. fit the boosting
```{r}
set.seed(101)
boost.boston = gbm(medv~., data = Boston[train,], distribution = "gaussian", n.trees = 10000, interaction.depth = 4)
summary(boost.boston)
```
# 3. Plot Partial Dependence Plots
```{r}
plot(boost.boston, i = "rm")
lot(boost.boston, i = "lstat")
```
# 4. Predicting Test Dataset with Different Number of Trees
```{r}
n.trees = seq(from = 100, to = 10000, by = 100)
boost.boston = gbm(medv~., data = Boston[train,], distribution = "gaussian", n.trees = 10000, shrinkage = 0.001)
pred.boston = predict(boost.boston, newdata = boston.test, n.trees = n.trees)
mse.tree = apply((pred.boston - medv.test) ^ 2, 2, mean)
plot(n.trees, mse.tree, pch = 19, ylab = "MSE", xlab = "trees")
```
# 5. Predicting Test Dataset with Different Lambda
```{r}
boost.boston.lambda = gbm(medv ~., data = Boston[train, ], distribution = "gaussian", n.trees = 10000, shrinkage = 0.01)
pred.boston.lambda = predict(boost.boston.lambda, newdata = boston.test, n.trees = n.trees)
mse.tree = apply((pred.boston - medv.test) ^ 2, 2, mean)
plot(n.trees, mse.tree, pch = 19, ylab = "MSE", xlab = "trees")

```

```{r}
detach("Boston")
```

